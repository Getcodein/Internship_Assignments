{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "###=================answer1==============================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# finding element for job search bar\n",
    "srch_jb = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "srch_jb.send_keys('Data Analyst')\n",
    "\n",
    "# finding element for job location bar\n",
    "search_loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "title_tags=[]\n",
    "locations_tags=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tags:\n",
    "    t=i.text\n",
    "    job_titles.append(t)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878eb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location=[]\n",
    "for i in locations_tags:\n",
    "    m=i.text\n",
    "    job_location.append(m)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b01f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=[]\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags:\n",
    "    n=i.text\n",
    "    company_name.append(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "experience_tags\n",
    "for i in experience_tags:\n",
    "    l=i.text\n",
    "    experience_required.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=company_name[:10]\n",
    "jobs['experience_required']=experience_required[:10]\n",
    "jobs['location']=job_location[:10]\n",
    "\n",
    "print(jobs)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5affabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============answer 2========================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# finding element for job search bar\n",
    "srch_jb = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "srch_jb.send_keys('Data Scientist')\n",
    "\n",
    "# finding element for job location bar\n",
    "search_loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "title_tags=[]\n",
    "locations_tags=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "print(title_tags)\n",
    "for i in title_tags:\n",
    "    t=i.text\n",
    "    job_titles.append(t)       \n",
    "\n",
    "\n",
    "print(job_titles)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f938bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "locations_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "job_location=[]\n",
    "for i in locations_tags:\n",
    "    m=i.text\n",
    "    job_location.append(m)       \n",
    "\n",
    "company_name=[]\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags:\n",
    "    n=i.text\n",
    "    company_name.append(n)\n",
    "    \n",
    "\n",
    "#-------------------creating data frame -------------------------\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['location']=job_location[:10]\n",
    "\n",
    "\n",
    "print(jobs)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ===============answer 3 ============================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# finding element for job search bar\n",
    "srch_jb = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "srch_jb.send_keys('Data Scientist')\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()\n",
    "time.sleep(10)\n",
    "#selecting location as Delhi-NCR on the second page\n",
    "srch_lc=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/i')\n",
    "srch_lc.click()\n",
    "time.sleep(10)\n",
    "\n",
    "#selecting salary as 3-6lakhs on the second page\n",
    "srch_sl =driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "srch_sl.click()\n",
    "time.sleep(10)\n",
    "\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "title_tags=[]\n",
    "locations_tags=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    t=i.text\n",
    "    job_titles.append(t)       \n",
    "\n",
    "\n",
    "locations_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "job_location=[]\n",
    "for i in locations_tags:\n",
    "    m=i.text\n",
    "    job_location.append(m)     \n",
    "\n",
    "\n",
    "company_name=[]\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags:\n",
    "    n=i.text\n",
    "    company_name.append(n)\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "experience_tags\n",
    "for i in experience_tags:\n",
    "    l=i.text\n",
    "    experience_required.append(l)\n",
    "\n",
    "# creating dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=company_name[:10]\n",
    "jobs['experience_required']=experience_required[:10]\n",
    "jobs['location']=job_location[:10]\n",
    "\n",
    "print(jobs)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ==========================answer 4=============================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# finding element for job search bar\n",
    "srch_jb = driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "srch_jb.send_keys('sunglasses')\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "price=[]\n",
    "Brand_name=[]\n",
    "Product_Description=[]\n",
    "\n",
    "for i in range(3):\n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_25b18c\"]')\n",
    "    for k in Price_tags:\n",
    "        m=k.text\n",
    "        price.append(m)       \n",
    "        \n",
    "    Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for l in Brand_tags:\n",
    "        n=l.text\n",
    "        Brand_name.append(n)      \n",
    "    \n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for h in product_tags:\n",
    "        p=h.text\n",
    "        Product_Description.append(p)\n",
    "        \n",
    "print(Brand_name[:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc77680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------creating data frame -------------------------\n",
    "shop=pd.DataFrame({})\n",
    "shop['Brand_name']=Brand_name[:100]\n",
    "shop['Product_Description']=Product_Description[:100]\n",
    "shop['price']=price[:100]\n",
    "\n",
    "\n",
    "print(shop)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69620725",
   "metadata": {},
   "outputs": [],
   "source": [
    "####=========================== answer 5=========================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "Rate=[]\n",
    "review=[]\n",
    "full_re=[]\n",
    "\n",
    "for page in range(10):\n",
    "    Rate_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in Rate_tags:\n",
    "        m=i.text\n",
    "        Rate.append(m)\n",
    "    time.sleep(10)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        k=i.text\n",
    "        review.append(k)\n",
    "    time.sleep(10)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        t=i.text\n",
    "        full_re.append(t)\n",
    "    time.sleep(10)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(10)\n",
    "\n",
    "print(len(Rate),len(review),len(full_re))\n",
    "print(review)\n",
    "    \n",
    "#-------------------creating data frame -------------------------\n",
    "Re=pd.DataFrame({})\n",
    "Re['Rate']=Rate\n",
    "Re['Review_summary']=review\n",
    "Re['Full_review']=full_re\n",
    "\n",
    "driver.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "####========================answer 6========================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# finding element for job search bar\n",
    "srch_jb = driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "srch_jb.send_keys('sneakers')\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_btn.click()\n",
    "time.sleep(20)\n",
    "\n",
    "\n",
    "Brand_name=[]\n",
    "Product_Description=[]\n",
    "price=[]\n",
    "\n",
    "for i in range(3):\n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for k in Price_tags:\n",
    "        m=k.text\n",
    "        price.append(m)       \n",
    "        \n",
    "    Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for l in Brand_tags:\n",
    "        n=l.text\n",
    "        Brand_name.append(n)      \n",
    "    \n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for h in product_tags:\n",
    "        p=h.text\n",
    "        Product_Description.append(p)\n",
    "        \n",
    "#print(Brand_name[:100])\n",
    "\n",
    "#-------------------creating data frame -------------------------\n",
    "shop=pd.DataFrame({})\n",
    "shop['Brand_name']=Brand_name[:100]\n",
    "shop['Product_Description']=Product_Description[:100]\n",
    "shop['price']=price[:100]\n",
    "\n",
    "\n",
    "print(shop)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12936681",
   "metadata": {},
   "outputs": [],
   "source": [
    "####====================answer 7==================================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "# finding element for job search bar\n",
    "srch_jb = driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "srch_jb.send_keys('Laptop')\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]')\n",
    "search_btn.click()\n",
    "time.sleep(10)\n",
    "\n",
    "#selecting CPU type as I7  on the second page\n",
    "srch_lc=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/li[13]/span/a/div/label/i')\n",
    "srch_lc.click()\n",
    "time.sleep(35)\n",
    "\n",
    "Price=[]\n",
    "Brand_name=[]\n",
    "rating=[]\n",
    "\n",
    "Price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for k in Price_tags:\n",
    "    m=k.text\n",
    "    price.append(m)       \n",
    "        \n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none puis-padding-right-small s-title-instructions-style\"]')\n",
    "for l in Brand_tags:\n",
    "    n=l.text\n",
    "    Brand_name.append(n)      \n",
    "    \n",
    "rating_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-base\"]')\n",
    "for h in rating_tags:\n",
    "    p=h.text\n",
    "    rating.append(p)\n",
    "    \n",
    "#-------------------creating data frame -------------------------\n",
    "shop=pd.DataFrame({})\n",
    "shop['Title']=Brand_name[:3]\n",
    "shop['Price']=price[:3]\n",
    "shop['Rating']=rating[:3]\n",
    "\n",
    "\n",
    "print(shop)\n",
    "\n",
    "driver.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####======================answer 7=======================================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "\n",
    "# clicking search button using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "quotes=[]\n",
    "author=[]\n",
    "typ_quote=[]\n",
    "\n",
    "for i in range(10):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for k in quote_tags:\n",
    "        m=k.text\n",
    "        quotes.append(m)\n",
    "    time.sleep(3)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for l in author_tags:\n",
    "        n=l.text\n",
    "        author.append(n)\n",
    "    time.sleep(3)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    typ_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for h in typ_tags:\n",
    "        p=h.text\n",
    "        typ_quote.append(p)\n",
    "    time.sleep(3)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "print(len(quotes),len(author),len(typ_quote))\n",
    "\n",
    "#-------------------creating data frame -------------------------\n",
    "shop=pd.DataFrame({})\n",
    "shop['Quote']=quotes\n",
    "shop['Author']=author\n",
    "shop['Type_Of_quotes']=typ_quote\n",
    "\n",
    "\n",
    "print(shop)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####=======================answer 9=====================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "\n",
    "\n",
    "# clicking GK option using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# clicking primemisnister list option using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "name=[]\n",
    "Born_Dead=[]\n",
    "Term_of_office=[]\n",
    "Remarks=[]\n",
    "\n",
    "name_tags=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "for k in name_tags:\n",
    "    m=k.text\n",
    "    name.append(m)\n",
    "\n",
    "\n",
    "Born_Dead_tags=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for l in Born_Dead_tags:\n",
    "    n=l.text\n",
    "    Born_Dead.append(n)   \n",
    "\n",
    "Term_of_office_tags=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[4]/p[1]')\n",
    "for h in Term_of_office_tags:\n",
    "    p=h.text\n",
    "    Term_of_office.append(p)\n",
    "    \n",
    "\n",
    "Remarks_tags=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for l in Remarks_tags:\n",
    "    t=l.text\n",
    "    Remarks.append(t) \n",
    "    \n",
    "#-------------------creating data frame -------------------------\n",
    "shop=pd.DataFrame({})\n",
    "shop['Name']=name\n",
    "shop['Born_Dead']=Born_Dead\n",
    "shop['Term_of_office']=Term_of_office\n",
    "shop['Remarks']=Remarks\n",
    "\n",
    "\n",
    "print(shop)\n",
    "\n",
    "driver.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ca020",
   "metadata": {},
   "outputs": [],
   "source": [
    "####===========================answer 10================================================\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from selenium.common.exceptions import staleElementRefereneceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#connecting to webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#url=\"https://www.naukri.com/\"\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "\n",
    "# clicking  dropdown option using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'//div[@class=\"m1-hamburger-button\"]')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# clicking features option using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[5]/button')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# clicking lists option using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# clicking 50car lists option using xpath function\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[1]/div[1]/div/div/div[2]/div/div[1]/h3/a')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "Name=[]\n",
    "Desc=[]\n",
    "price=[]\n",
    "\n",
    "Name_tags=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for k in Name_tags:\n",
    "    m=k.text\n",
    "    Name.append(m)\n",
    "\n",
    "        \n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,'//strong')\n",
    "for h in price_tags:\n",
    "    p=h.text\n",
    "    price.append(p)\n",
    "\n",
    "\n",
    "\n",
    "#description = []\n",
    "#description_50expcars = driver.find_elements(By.XPATH,'/html/body/div[2]/div[7]/div[2]/div[1]/div[2]/div[1]/p')\n",
    "#for k in description_50expcars:\n",
    " #   description.append(k.text)\n",
    "\n",
    "#time.sleep(3)\n",
    "#print(len(description))\n",
    "#print(description)\n",
    "\n",
    "#for removing the price row whoch is also included in descroption data-\n",
    "#desc_list=[]\n",
    "#for i in range(4,103,2):\n",
    "#    desc_list.append(description[i])\n",
    "\n",
    "#-------------------creating data frame -------------------------\n",
    "shop=pd.DataFrame({})\n",
    "shop['Name']=Name\n",
    "shop['price']=price\n",
    "\n",
    "\n",
    "print(shop)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdb342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
